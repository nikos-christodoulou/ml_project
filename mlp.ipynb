{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7541702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from logistic_regression import load_data, sigmoid, create_feature_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45001ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the dataset\n",
    "# plot 5 random images from the training set\n",
    "n = 100\n",
    "sqrt_n = int( n**0.5 )\n",
    "samples = np.random.randint(X_train.shape[0], size=n)\n",
    "\n",
    "plt.figure( figsize=(11,11) )\n",
    "\n",
    "cnt = 0\n",
    "for i in samples:\n",
    "    cnt += 1\n",
    "    plt.subplot( sqrt_n, sqrt_n, cnt )\n",
    "    plt.subplot( sqrt_n, sqrt_n, cnt ).axis('off')\n",
    "    plt.imshow( X_train[i].reshape(28,28), cmap='gray'  )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31996e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset.\n",
    "X_train, X_test, y_train, y_test = load_data()\n",
    "\n",
    "#split our training dataset to train and validation set.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, train_size=0.8, random_state=42) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94e6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "\n",
    "#Creating training, test and validation vectors.\n",
    "create_feature_vectors(784, X_train)\n",
    "create_feature_vectors(784, X_test)\n",
    "create_feature_vectors(784, X_val)    \n",
    "\n",
    "#normalize data to get values between (0,1)\n",
    "X_train = X_train.astype(float) / 255\n",
    "X_test = X_test.astype(float) / 255\n",
    "X_val = X_val.astype(float) / 255\n",
    "\n",
    "#We add a column of 1s to each data vector for the bias.\n",
    "X_train = np.hstack( (np.ones((X_train.shape[0], 1) ), X_train))\n",
    "X_test = np.hstack( (np.ones((X_test.shape[0], 1) ), X_test))\n",
    "X_val = np.hstack( (np.ones((X_val.shape[0], 1) ), X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214b6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=2    #We've got only 2 classes\n",
    "N, D = X_train.shape\n",
    "Winit = 0.5 * np.ones((K, D))\n",
    "options = [500, 1e-6, 0.5/N]# Maximum number of iteration of gradient ascend, Tolerance, Learning rate\n",
    "\n",
    "\"\"\"\n",
    "We will have 32 nodes on the single hidden layer.\n",
    "From the input layer to the hidden layer we will have 784 * 32 = 25,088 weights.\n",
    "While we just have K=2 classes, there will be 2 * 32 = 64 weights from the hidden layer to the output layer. \n",
    "This brings us to a total 25,088 + 64 + 2 = 25,154 parameters.\n",
    "\"\"\"\n",
    "\n",
    "def cost_grad_sigmoid(W, X, t, lamda):\n",
    "    E = 0\n",
    "    N, D = X.shape\n",
    "    K = t.shape[1]\n",
    "    \n",
    "    y = sigmoid( X.dot(W) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
