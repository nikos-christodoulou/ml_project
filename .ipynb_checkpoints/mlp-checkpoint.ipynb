{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7541702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from logistic_regression import load_data, sigmoid, create_feature_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31996e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset.\n",
    "X_train, X_test, y_train, y_test = load_data()\n",
    "\n",
    "#split our training dataset to train and validation set.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, train_size=0.8, random_state=42) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b94e6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "\n",
    "#Creating training, test and validation vectors.\n",
    "create_feature_vectors(784, X_train)\n",
    "create_feature_vectors(784, X_test)\n",
    "create_feature_vectors(784, X_val)    \n",
    "\n",
    "#normalize data to get values between (0,1)\n",
    "X_train = X_train.astype(float) / 255\n",
    "X_test = X_test.astype(float) / 255\n",
    "X_val = X_val.astype(float) / 255\n",
    "\n",
    "#We add a column of 1s to each data vector for the bias.\n",
    "X_train = np.hstack( (np.ones((X_train.shape[0], 1) ), X_train))\n",
    "X_test = np.hstack( (np.ones((X_test.shape[0], 1) ), X_test))\n",
    "X_val = np.hstack( (np.ones((X_val.shape[0], 1) ), X_val))\n",
    "\n",
    "#Taking the true labels for the 6th class.\n",
    "#y_train = y_train[:,1]\n",
    "#y_val = y_val[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "706f06d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ...\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]]\n",
      "(9071, 2)\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " ...\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]]\n",
      "(9071, 785)\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_train.shape)\n",
    "print(y_val)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33ac89cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7292/1640190236.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "#View the dataset\n",
    "# plot 5 random images from the training set\n",
    "n = 100\n",
    "sqrt_n = int( n**0.5 )\n",
    "samples = np.random.randint(X_train.shape[0], size=n)\n",
    "\n",
    "plt.figure( figsize=(11,11) )\n",
    "\n",
    "cnt = 0\n",
    "for i in samples:\n",
    "    cnt += 1\n",
    "    plt.subplot( sqrt_n, sqrt_n, cnt )\n",
    "    plt.subplot( sqrt_n, sqrt_n, cnt ).axis('off')\n",
    "    plt.imshow( X_train[i].reshape(28,28), cmap='gray'  )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "214b6045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe will need one function for the forward pass of the nn\\nand one function for the back-propagation pass for the weights.\\n\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=2    #We've got only 2 classes\n",
    "N, D = X_train.shape\n",
    "Winit = 0.5 * np.ones((K, D))   #(2,785)\n",
    "options = [500, 1e-6, 0.5/N]# Maximum number of iteration of gradient ascend, Tolerance, Learning rate\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "We will have m nodes on the single hidden layer.\n",
    "From the input layer to the hidden layer we will have 785 * m weights.\n",
    "While we just have K=2 classes, there will be m weights from the hidden layer to the output layer. \n",
    "\"\"\"\n",
    "\n",
    "def forward_gradient(X, W, t, lamda):\n",
    "    #X: NxD\n",
    "    #W: KxD\n",
    "    #t: NxD\n",
    "    \n",
    "    E = 0\n",
    "    N, D = X.shape\n",
    "    K = t.shape[1]\n",
    "    \n",
    "    #we use the logistic sigmoid as the activation function\n",
    "    y = sigmoid( X.dot(W.T) )\n",
    "    \n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "            E += t[n][k] * np.log( y[n][k] )\n",
    "    E -= lamda * np.sum( np.square( W ) ) / 2\n",
    "    \n",
    "    gradEw = np.dot( (t-y).T, X ) - lamda * W\n",
    "    \n",
    "    return E, gradEw\n",
    "\n",
    "\"\"\"\n",
    "We will need one function for the forward pass of the nn\n",
    "and one function for the back-propagation pass for the weights.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa93aa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(t, X, lamda, Winit, options):\n",
    "    \n",
    "    W = Winit\n",
    "    \n",
    "    _iter = options[0] #max_iterations\n",
    "    tol = options[1] #tolerance\n",
    "    lr = options[2] #learning rate\n",
    "    \n",
    "    Ewol = -np.inf\n",
    "    costs = []\n",
    "    for i in range(1, _iter+1):\n",
    "        Ew, gradEw = forward_gradient(X, W, t, lamda)\n",
    "        \n",
    "        costs.append(Ew)\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print('Iteration : %d, Cost function :%f' % (i, Ew))\n",
    "        \n",
    "        if np.abs(Ew - Ewol) < tol:\n",
    "            break\n",
    "        #update W with gradient ascent\n",
    "        W = W + lr * gradEw\n",
    "        \n",
    "        Ewol = Ew\n",
    "    \n",
    "    return W, costs\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11b5a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 50, Cost function :-768.766496\n",
      "Iteration : 100, Cost function :-673.158806\n",
      "Iteration : 150, Cost function :-624.517187\n",
      "Iteration : 200, Cost function :-592.082327\n",
      "Iteration : 250, Cost function :-567.763132\n",
      "Iteration : 300, Cost function :-548.328550\n",
      "Iteration : 350, Cost function :-532.169650\n",
      "Iteration : 400, Cost function :-518.367489\n",
      "Iteration : 450, Cost function :-506.346133\n",
      "Iteration : 500, Cost function :-495.719664\n"
     ]
    }
   ],
   "source": [
    "#Initializing w for the gradient ascent\n",
    "Winit = np.zeros((K, D))\n",
    "lamda = 0.1\n",
    "\n",
    "W, costs = back_propagation(y_train, X_train, lamda, Winit, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3c19665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W, X):\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    #We will use 0.5 as the threshold to decide\n",
    "    #on which class it belongs\n",
    "    pred = np.zeros((m,1));\n",
    "    pred = sigmoid(X.dot(W.T))\n",
    "    prob = pred\n",
    "    pred = pred > 0.5 - 1e-6\n",
    "    \n",
    "    return pred, prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "001d3cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training set 0.9813691985448132\n",
      "Accuracy of validation set 0.9761904761904762\n"
     ]
    }
   ],
   "source": [
    "#test the mlp on our training and validation set.\n",
    "pred_train, prob_train = predict(W, X_train)\n",
    "pred_val, prob_val = predict(W, X_val)\n",
    "#Accuracy\n",
    "print( 'Accuracy of training set', np.mean( pred_train.astype('int') == y_train ) )\n",
    "print( 'Accuracy of validation set', np.mean( pred_val.astype('int') == y_val ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72bcbc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.squeeze(costs))\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per tens)')\n",
    "plt.title(\"Learning rate =\" + str(format(options[2], 'f')))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "249199ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'pred_val1' is an invalid keyword argument for print()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7292/593282908.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_val1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_val2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#pred_val[np.where(pred_val == \" True False\")] = \"1 0\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'pred_val1' is an invalid keyword argument for print()"
     ]
    }
   ],
   "source": [
    "pred_val1 = pred_val[:,0]\n",
    "pred_val2 = pred_val[:,1]\n",
    "print(pred_val[0])\n",
    "print(pred_val)\n",
    "#pred_val[np.where(pred_val == \" True False\")] = \"1 0\"\n",
    "print(pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c14e99cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2268, 1)\n",
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " ...\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "(array([   3,    4,    5, ..., 2258, 2261, 2264], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "#pred_val1[np.where(pred_val1 == True)] = 1\n",
    "#pred_val1 = pred_val1.reshape(-1,1)\n",
    "\n",
    "print(pred_val1.shape)\n",
    "print(pred_val1)\n",
    "\n",
    "print(np.where(pred_val2 != False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1390f508",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7292/4089768143.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# plot n misclassified examples from the Test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0msqrt_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: a must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "faults = (y_val != pred_val).astype(int)\n",
    "\n",
    "incorrect_indices = np.where(faults != 0)\n",
    "\n",
    "# plot n misclassified examples from the Test set\n",
    "n = 25\n",
    "samples = np.random.choice(faults, n)\n",
    "sqrt_n = int( n ** 0.5 )\n",
    "\n",
    "plt.figure( figsize=(11,13) )\n",
    "\n",
    "cnt = 0\n",
    "for i in samples:\n",
    "    cnt += 1\n",
    "    plt.subplot( sqrt_n, sqrt_n, cnt )\n",
    "    plt.subplot( sqrt_n, sqrt_n, cnt ).axis('off')\n",
    "    plt.imshow( X_test[i,1:].reshape(28,28)*255, cmap='gray' )\n",
    "    plt.title(\"True: \"+str(np.argmax(y_val,1)[i])+ \"\\n Predicted: \"+ str(pred_val[i]))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c667049c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]]\n",
      "(array([  69,   69,   88,   88,  115,  115,  217,  217,  238,  238,  301,\n",
      "        301,  329,  329,  472,  472,  473,  473,  474,  474,  522,  522,\n",
      "        587,  587,  602,  602,  628,  628,  663,  663,  813,  813,  836,\n",
      "        836,  867,  867,  882,  882,  898,  898,  899,  899,  900,  900,\n",
      "        909,  909,  969,  969, 1008, 1008, 1028, 1028, 1068, 1068, 1128,\n",
      "       1128, 1145, 1145, 1149, 1149, 1214, 1214, 1226, 1226, 1235, 1235,\n",
      "       1271, 1271, 1300, 1300, 1476, 1476, 1490, 1490, 1593, 1593, 1608,\n",
      "       1608, 1695, 1695, 1744, 1744, 1906, 1906, 1947, 1947, 1958, 1958,\n",
      "       2024, 2024, 2032, 2032, 2060, 2060, 2069, 2069, 2120, 2120, 2162,\n",
      "       2162, 2203, 2203, 2213, 2213, 2241, 2241, 2267, 2267], dtype=int64), array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
      "      dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "differences = (y_val != pred_val).astype(int)\n",
    "faults = np.where(difference != 0).shape[0]\n",
    "\n",
    "print(faults)\n",
    "incorrect_indices = np.where(faults != 0)\n",
    "print(incorrect_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
